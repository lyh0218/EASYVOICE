import logging
import os
from typing import Dict
from pydub import AudioSegment
from pydub.silence import split_on_silence
import subprocess
import sys
from opencc import OpenCC

'''
    å¤šåŠŸèƒ½éŸ³é¢‘/è§†é¢‘å¤„ç†å·¥å…·
'''


# æ–‡æœ¬æ—¶é—´ç±»
class TextTime:
    def __init__(self, text, time):
        self.text = text
        self.time = time
        self.wav_path = "NOT"

# mp4 -> wav
def mp4_to_wav_pydub(mp4_path, wav_path):
    audio = AudioSegment.from_file(mp4_path, format="mp4")
    audio = audio.set_frame_rate(22050).set_channels(1) #é‡‡æ ·ç‡ å•å£°é“
    audio.export(wav_path, format="wav", parameters=["-acodec", "pcm_s16le"])
    return wav_path
# äººå£°åˆ†ç¦»
def separate_audio(input_audio_file, output_dir):
    input_audio_file = mp4_to_wav_pydub(input_audio_file,"data/temp/view_temp/input.wav")
    if os.name == "nt":
        possible_paths = [
            os.path.join(sys.prefix, "Scripts", "demucs.exe"),
            os.path.join(os.environ.get("USERPROFILE", ""), ".local", "bin", "demucs.exe")
        ]
    else:
        possible_paths = [
            os.path.join(sys.prefix, "bin", "demucs"),
            os.path.join(os.environ.get("HOME", ""), ".local", "bin", "demucs")
        ]
    demucs_path = None
    for path in possible_paths:
        if os.path.exists(path):
            demucs_path = path
            break
    if demucs_path is None:
        print("âŒ æ— æ³•æ‰¾åˆ° demucs å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè¯·ç¡®ä¿å·²å®‰è£… demucsã€‚")
        return
    if not os.path.exists(input_audio_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_audio_file}")
        return
    try:
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“¢ å¼€å§‹åˆ†ç¦»éŸ³é¢‘: {input_audio_file}")
        command = [
            demucs_path,
            '-n', 'htdemucs',
            input_audio_file,
            '-o', output_dir
        ]
        subprocess.run(command, check=True)
        model_name = 'htdemucs'
        input_name = os.path.splitext(os.path.basename(input_audio_file))[0]
        vocal_path = os.path.join(output_dir, model_name, input_name, 'vocals.wav')
        bass_path = os.path.join(output_dir, model_name, input_name, 'bass.wav')
        drums_path = os.path.join(output_dir, model_name, input_name, 'drums.wav')
        other_path = os.path.join(output_dir, model_name, input_name, 'other.wav')
        accompaniment_path = os.path.join(output_dir, model_name, input_name, 'accompaniment.wav')
        if os.path.exists(vocal_path):
            print(f"âœ… äººå£°åˆ†ç¦»å®Œæˆï¼š{vocal_path}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°äººå£°åˆ†ç¦»ç»“æœï¼Œè¯·æ£€æŸ¥è¾“å‡ºç›®å½•ã€‚")
        if os.path.exists(accompaniment_path):
            print(f"âœ… ä¼´å¥åˆ†ç¦»å®Œæˆï¼š{accompaniment_path}")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ä¼´å¥åˆ†ç¦»ç»“æœï¼Œè¯·æ£€æŸ¥è¾“å‡ºç›®å½•ã€‚")
        return [vocal_path,bass_path,drums_path,other_path]
    except subprocess.CalledProcessError as e:
        print(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

def split_audio_on_silence(vocal_output_path, output_folder):
    """æŒ‰é™éŸ³è¿›è¡Œåˆ†æ®µå¹¶ä¿å­˜"""
    try:
        # åŠ è½½åˆ†ç¦»åçš„äººå£°éŸ³é¢‘
        audio = AudioSegment.from_wav(vocal_output_path)
        # æŒ‰é™éŸ³è¿›è¡Œåˆ†æ®µ
        chunks = split_on_silence(audio, min_silence_len=100, silence_thresh=-45, keep_silence=200, seek_step=10)
        # ä¿å­˜åˆ†æ®µéŸ³é¢‘
        os.makedirs(output_folder, exist_ok=True)
        valid_count = 1
        for i, chunk in enumerate(chunks):
            # è°ƒæ•´éŸ³é¢‘ä»¥ç¬¦åˆ è®­ç»ƒè¦æ±‚
            chunk = chunk.set_frame_rate(22050).set_sample_width(2).set_channels(1)
            # ä¿å­˜éŸ³é¢‘å¹¶ä½¿ç”¨æœ‰åºç¼–å·
            output_path = os.path.join(output_folder, f"output_clip_{valid_count}.wav")
            chunk.export(output_path, format="wav")
            valid_count += 1
        logging.info(f"éŸ³é¢‘åˆ†æ®µä¿å­˜å®Œæˆï¼Œå…±ä¿å­˜ {valid_count - 1} ä¸ªç‰‡æ®µ")
    except Exception as e:
        logging.error(f"éŸ³é¢‘åˆ†æ®µä¿å­˜æ—¶å‡ºé”™: {e}")

def get_wav_text(model,audio_file_path):
    cc_model = OpenCC('t2s')
    if os.path.exists(audio_file_path):
        result = model.transcribe(audio_file_path, language="zh", temperature=0.2, beam_size=5)["text"].strip()
        cc_model.convert(result)
    else:
        result = None
    return result

def recognize_audio_files(model):
    import wave
    audio_folder = "data/temp/view_temp/clips"
    result_dict = {}
    total_time = 0
    def get_file_number(file_name):
        try:
            return int(file_name.split("_")[-1].split(".")[0])
        except (IndexError, ValueError):
            return float('inf')
    audio_files = sorted(os.listdir(audio_folder), key=get_file_number)
    for filename in audio_files:
        if filename.startswith("output_clip_") and filename.endswith(".wav"):
            audio_path = os.path.join(audio_folder, filename)
            try:
                with wave.open(audio_path, 'r') as wf:
                    frames = wf.getnframes()
                    rate = wf.getframerate()
                    audio_duration = frames / float(rate)
                text = get_wav_text(model, audio_path)
                result_dict[filename] = TextTime(text, total_time)
                total_time += audio_duration * 1000
            except Exception as e:
                print(f"å¤„ç† {filename} æ—¶å‡ºé”™: {e}")
    return result_dict

def traverse_audio_dict(audio_dict):
    for audio_file, text_time_obj in audio_dict.items():
        print(f"éŸ³é¢‘æ–‡ä»¶å: {audio_file}")
        print(f"è¯†åˆ«æ–‡æœ¬: {text_time_obj.text}")
        print(f"æ—¶é—´æˆ³: {text_time_obj.time}")
        print("-" * 30)

def combine_accompaniments(bass_path, drums_path, other_path, output_path):
    bass = AudioSegment.from_wav(bass_path)
    drums = AudioSegment.from_wav(drums_path)
    other = AudioSegment.from_wav(other_path)

    combined = bass.overlay(drums).overlay(other)
    combined.export(output_path, format="wav")
    return output_path

def mix_audio_with_accompaniment(clip_dict):
    accompaniment_path = "data/temp/view_temp/accompaniment.wav"
    try:
        accompaniment = AudioSegment.from_wav(accompaniment_path)
        for clip_name, clip_obj in clip_dict.items():
            if clip_obj.wav_path != "NOT":
                # åŠ è½½è¦æ’å…¥çš„éŸ³é¢‘
                audio_clip = AudioSegment.from_wav(clip_obj.wav_path)
                # åœ¨æŒ‡å®šæ—¶é—´æ’å…¥éŸ³é¢‘
                insert_time = clip_obj.time
                if insert_time <= len(accompaniment):
                    accompaniment = accompaniment.overlay(audio_clip, position=insert_time)
                else:
                    print(f"æ’å…¥æ—¶é—´ {insert_time} è¶…å‡ºä¼´å¥é•¿åº¦ï¼Œè·³è¿‡ {clip_name}ã€‚")
        output_path = "data/temp/view_temp/output.wav"
        accompaniment.export(output_path, format="wav")
        print(f"æ··åˆåçš„éŸ³é¢‘å·²ä¿å­˜åˆ° {output_path}")
    except FileNotFoundError:
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ°ä¼´å¥æ–‡ä»¶æˆ–éŸ³é¢‘å‰ªè¾‘æ–‡ä»¶ã€‚")
    except Exception as e:
        print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{e}")

def make_view(view_path):
    audio_path = "data/temp/view_temp/output.wav"
    output_path = "data/temp/view_temp/output_new.mp4"
    command = [
        "ffmpeg",
        "-i", view_path,
        "-i", audio_path,
        "-c:v", "copy",
        "-map", "0:v:0",
        "-map", "1:a:0",
        "-shortest",
        output_path
    ]
    subprocess.run(command)
    return output_path

def make_view_save(view_path,output_path):
    audio_path = "data/temp/view_temp/output.wav"
    command = [
        "ffmpeg",
        "-i", view_path,
        "-i", audio_path,
        "-c:v", "copy",
        "-map", "0:v:0",
        "-map", "1:a:0",
        "-shortest",
        output_path
    ]
    subprocess.run(command)
    return output_path

def add_subtitles_to_video(audio_video_dict: Dict[str, TextTime], video_path: str, output_video_path: str):
    """
    ä½¿ç”¨å­—å…¸ä¸­çš„éŸ³é¢‘ä¿¡æ¯ä¸ºè§†é¢‘æ·»åŠ å­—å¹•ã€‚
    :param audio_video_dict: å­—å…¸æ ¼å¼ {éŸ³é¢‘æ–‡ä»¶è·¯å¾„: TextTimeå¯¹è±¡}
    :param video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
    :param output_video_path: è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„
    """
    subtitle_file = "subtitles.srt"

    # åˆ›å»º SRT å­—å¹•æ–‡ä»¶
    with open(subtitle_file, "w", encoding="utf-8") as srt_file:
        idx = 1
        for audio_file, text_time in audio_video_dict.items():
            # è·å–å­—å…¸ä¸­çš„ TextTime å¯¹è±¡
            text = text_time.text
            start_time_ms = text_time.time  # å­—å¹•çš„å¼€å§‹æ—¶é—´ï¼Œå•ä½ä¸ºæ¯«ç§’
            wav_path = text_time.wav_path

            # å¦‚æœ wav_path ä¸º "NOT"ï¼Œè·³è¿‡æ­¤æ¡è®°å½•
            if wav_path == "NOT":
                continue

            # è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿
            audio_file_path = os.path.abspath(wav_path)  # è·å–éŸ³é¢‘æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
            if not os.path.exists(audio_file_path):
                print(f"Error: Audio file '{wav_path}' not found.")
                continue

            audio = AudioSegment.from_wav(audio_file_path)
            audio_duration_ms = len(audio)  # è·å–éŸ³é¢‘æ–‡ä»¶çš„æ—¶é•¿ï¼Œå•ä½æ˜¯æ¯«ç§’

            # è®¡ç®—ç»“æŸæ—¶é—´
            start_time_sec = start_time_ms / 1000  # å°†å¼€å§‹æ—¶é—´è½¬æ¢ä¸ºç§’
            end_time_sec = (start_time_ms + audio_duration_ms) / 1000  # ç»“æŸæ—¶é—´ = å¼€å§‹æ—¶é—´ + éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰

            # å†™å…¥ SRT æ ¼å¼å­—å¹•å†…å®¹
            srt_file.write(f"{idx}\n")
            srt_file.write(f"{format_time(start_time_sec)} --> {format_time(end_time_sec)}\n")
            srt_file.write(f"{text}\n\n")

            idx += 1

    # ä½¿ç”¨ subprocess æ‰§è¡Œ ffmpeg å‘½ä»¤è¡Œï¼Œæ·»åŠ å­—å¹•
    command = [
        "ffmpeg",
        "-i", video_path,
        "-vf", f"subtitles={subtitle_file}",
        "-c:a", "copy",  # ä¿ç•™åŸéŸ³é¢‘æµä¸å˜
        output_video_path
    ]

    subprocess.run(command, check=True)  # æ‰§è¡Œå‘½ä»¤è¡Œ

    # åˆ é™¤ä¸´æ—¶ SRT æ–‡ä»¶
    os.remove(subtitle_file)


def format_time(seconds: float) -> str:
    """å°†ç§’è½¬æ¢ä¸º SRT æ—¶é—´æ ¼å¼ (HH:MM:SS,MS)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = seconds % 60
    milliseconds = int((seconds - int(seconds)) * 1000)
    return f"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}"
